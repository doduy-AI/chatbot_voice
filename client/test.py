import asyncio
import websockets
import numpy as np
import sounddevice as sd
from scipy.io.wavfile import write
import speech_recognition as sr
import time
import queue
import json

# ====== C·∫§U H√åNH ======
SAMPLE_RATE_TTS = 24000  
REC_SAMPLE_RATE = 44100
DURATION = 5
TTS_URI = "ws://116.106.20.52:23658/api/v1/tts/ws/doduy001"

# ====== STT (Speech to Text) ======
def record_audio(duration=DURATION, fs=REC_SAMPLE_RATE, filename="input.wav"):
    print(f"\nüé§ Ghi √¢m {duration}s... (M·ªùi b·∫°n n√≥i)")
    try:    
        recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')
        sd.wait()
        write(filename, fs, (recording * 32767).astype(np.int16))
        return filename
    except Exception as e:
        print(f"‚ùå L·ªói ghi √¢m: {e}")
        return None

def stt(audio_path):
    recognizer = sr.Recognizer()
    try:
        with sr.AudioFile(audio_path) as source:
            audio_data = recognizer.record(source)
            text = recognizer.recognize_google(audio_data, language='vi-VN')
            print(f"üë§ B·∫°n n√≥i: {text}")
            return text
    except Exception:
        print("‚ùì Kh√¥ng nghe r√µ...")
        return None

# ====== TTS (Text to Speech) - B·∫¢N B·ªî SUNG LOG DEBUG ======
async def tts_speak(websocket, text):
    start_time = time.perf_counter()
    
    # 1. G·ª≠i y√™u c·∫ßu
    await websocket.send(text)
    print(f"üöÄ ƒê√£ g·ª≠i: '{text}'")
    
    audio_queue = queue.Queue()
    first_chunk_received = False
    total_samples = 0
    chunk_count = 0
    
    def callback(outdata, frames, time_info, status):
        try:
            data = audio_queue.get_nowait()
            if len(data) < len(outdata):
                outdata[:len(data), 0] = data
                outdata[len(data):, 0] = 0
            else:
                outdata[:, 0] = data[:len(outdata)]
        except queue.Empty:
            outdata.fill(0)

    with sd.OutputStream(samplerate=SAMPLE_RATE_TTS, channels=1, dtype='int16', callback=callback, blocksize=1024) as stream:
        print("üîä ƒêang ƒë·ª£i lu·ªìng √¢m thanh t·ª´ Server...")
        
        while True:
            try:
                response = await websocket.recv()
                
                # CASE 1: Nh·∫≠n tin nh·∫Øn vƒÉn b·∫£n (Control/Status)
                if isinstance(response, str):
                    print(f"üìù [TEXT FRAME]: {response}")
                    if response == "END_OF_STREAM":
                        print(f"üèÅ Nh·∫≠n t√≠n hi·ªáu k·∫øt th√∫c. T·ªïng m·∫´u nh·∫≠n ƒë∆∞·ª£c: {total_samples}")
                        while not audio_queue.empty():
                            await asyncio.sleep(0.1)
                        await asyncio.sleep(0.5)
                        break
                    continue
                
                # CASE 2: Nh·∫≠n d·ªØ li·ªáu √¢m thanh (Binary)
                chunk_count += 1
                if not first_chunk_received:
                    latency = (time.perf_counter() - start_time) * 1000
                    print(f"‚è±Ô∏è TTFA (ƒê·ªô tr·ªÖ chunk ƒë·∫ßu): {latency:.2f} ms")
                    first_chunk_received = True
                
                # Gi·∫£i m√£ d·ªØ li·ªáu (S·ª≠ d·ª•ng int16 v√¨ server c·ªßa b·∫°n ƒë√£ convert pcm16)
                chunk = np.frombuffer(response, dtype='int16')
                total_samples += len(chunk)
                
                # --- LOG DEBUG CHI TI·∫æT ---
                v_min, v_max = np.min(chunk), np.max(chunk)
                print(f"üì¶ [Chunk #{chunk_count}] Size: {len(chunk)} | Min: {v_min} | Max: {v_max}")
                
                # N·∫øu bi√™n ƒë·ªô Min/Max ƒë·ªÅu b·∫±ng 0, c√≥ nghƒ©a l√† server ƒëang g·ª≠i ƒëo·∫°n im l·∫∑ng
                if v_min == 0 and v_max == 0:
                    print("‚ö†Ô∏è C·∫£nh b√°o: Chunk n√†y ho√†n to√†n l√† kho·∫£ng l·∫∑ng!")

                # ƒê∆∞a v√†o h√†ng ƒë·ª£i ƒë·ªÉ ph√°t
                for i in range(0, len(chunk), 1024):
                    sub_chunk = chunk[i:i+1024]
                    if len(sub_chunk) < 1024:
                        padded = np.zeros(1024, dtype='int16')
                        padded[:len(sub_chunk)] = sub_chunk
                        audio_queue.put(padded)
                    else:
                        audio_queue.put(sub_chunk)
                        
            except websockets.exceptions.ConnectionClosed:
                print("‚ùå L·ªñI: Server ng·∫Øt k·∫øt n·ªëi WebSocket ƒë·ªôt ng·ªôt.")
                break
            except Exception as e:
                print(f"‚ùå L·ªñI TRONG LU·ªíNG NH·∫¨N: {e}")
                break

    print(f"‚úÖ Robot n√≥i xong. T·ªïng c·ªông nh·∫≠n {chunk_count} chunks.")

async def voice_loop():
    print("ü§ñ Robot VieNeu-TTS s·∫µn s√†ng!")
    try:
        async with websockets.connect(TTS_URI) as websocket:
            print(f"üîó ƒê√£ k·∫øt n·ªëi t·ªõi {TTS_URI}")
            while True:
                filename = record_audio()
                if not filename: continue
                
                text_input = stt(filename)
                if not text_input: continue
                
                await tts_speak(websocket, text_input)
                await asyncio.sleep(0.5)
    except Exception as e:
        print(f"‚ùå L·ªói k·∫øt n·ªëi: {e}")

if __name__ == "__main__":
    asyncio.run(voice_loop())